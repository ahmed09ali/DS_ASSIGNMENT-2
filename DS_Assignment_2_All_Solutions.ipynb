{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54603f15",
   "metadata": {},
   "source": [
    "## 1. Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262ad8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    A   B     C    D      E        Date\n",
       " 1  93  24  64.0  dog  apple  2023-01-02\n",
       " 2  15   3  60.0  cat  apple  2023-01-03\n",
       " 5  21   2  33.0  dog  apple  2023-01-06\n",
       " 7  87  30  76.0  dog  apple  2023-01-08,\n",
       "     A   B     C    D      E        Date\n",
       " 0  52  88  52.0  cat    NaN  2023-01-01\n",
       " 1  93  24  64.0  dog  apple  2023-01-02\n",
       " 2  15   3  60.0  cat  apple  2023-01-03\n",
       " 3  72  22  52.0  dog  apple  2023-01-04\n",
       " 4  61  53  21.0  cat    NaN  2023-01-05\n",
       " 5  21   2  33.0  dog  apple  2023-01-06\n",
       " 6  83  88  52.0  cat  apple  2023-01-07\n",
       " 7  87  30  76.0  dog  apple  2023-01-08\n",
       " 8  75  38  58.0  cat    NaN  2023-01-09\n",
       " 9  75   2  52.0  dog  apple  2023-01-10,\n",
       "     A   B     C    D      E        Date\n",
       " 0  52  88   NaN  cat  apple  2023-01-01\n",
       " 1  93  24  64.0  dog  apple  2023-01-02\n",
       " 2  15   3  60.0  cat  apple  2023-01-03\n",
       " 3  72  22   NaN  dog  apple  2023-01-04\n",
       " 4  61  53  21.0  cat  apple  2023-01-05\n",
       " 5  21   2  33.0  dog  apple  2023-01-06\n",
       " 6  83  88   NaN  cat  apple  2023-01-07\n",
       " 7  87  30  76.0  dog  apple  2023-01-08\n",
       " 8  75  38  58.0  cat  apple  2023-01-09\n",
       " 9  75   2   NaN  dog  apple  2023-01-10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\syeda\\Downloads\\sample_data.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropna = df.dropna()\n",
    "\n",
    "# Replace missing numerical values with mean\n",
    "df_fill_mean = df.copy()\n",
    "df_fill_mean['C'] = df_fill_mean['C'].fillna(df_fill_mean['C'].mean())\n",
    "\n",
    "# Replace missing categorical values with mode\n",
    "df_fill_mode = df.copy()\n",
    "df_fill_mode['E'] = df_fill_mode['E'].fillna(df_fill_mode['E'].mode()[0])\n",
    "\n",
    "df_dropna, df_fill_mean, df_fill_mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa8bde",
   "metadata": {},
   "source": [
    "## 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae164c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8424\\505697719.py\", line 3, in <module>\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 14, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\__init__.py\", line 274, in <module>\n",
      "    from ._csr import *\n",
      "  File \"c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA_plus_B\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt_A\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     __check_build,\n\u001b[0;32m     71\u001b[0m     _distributor_init,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\__init__.py:274\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix, _array_doc_to_matrix\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df['A_plus_B'] = np.add(df['A'], df['B'])\n",
    "df['sqrt_A'] = np.sqrt(df['A'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['A_normalized'] = scaler.fit_transform(df[['A']])\n",
    "\n",
    "df[['A', 'B', 'A_plus_B', 'sqrt_A', 'A_normalized']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b3291",
   "metadata": {},
   "source": [
    "## 3. Merging and Joining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72f65fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   A_x  B_x     C    D      E        Date  key  A_y  B_y\n",
       " 0   52   88   0.0  cat      0  2023-01-01    0   52   88\n",
       " 1   93   24  64.0  dog  apple  2023-01-02    1   93   24\n",
       " 2   15    3  60.0  cat  apple  2023-01-03    2   15    3\n",
       " 3   72   22   0.0  dog  apple  2023-01-04    3   72   22\n",
       " 4   61   53  21.0  cat      0  2023-01-05    4   61   53\n",
       " 5   21    2  33.0  dog  apple  2023-01-06    5   21    2\n",
       " 6   83   88   0.0  cat  apple  2023-01-07    6   83   88\n",
       " 7   87   30  76.0  dog  apple  2023-01-08    7   87   30\n",
       " 8   75   38  58.0  cat      0  2023-01-09    8   75   38\n",
       " 9   75    2   0.0  dog  apple  2023-01-10    9   75    2,\n",
       "    id val1  ref val2\n",
       " 0   1    x  NaN  NaN\n",
       " 1   2    y  2.0    a,\n",
       "     A   B     C    D      E        Date  key\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01    0\n",
       " 1  93  24  64.0  dog  apple  2023-01-02    1\n",
       " 2  15   3  60.0  cat  apple  2023-01-03    2\n",
       " 3  72  22   NaN  dog  apple  2023-01-04    3\n",
       " 4  61  53  21.0  cat    NaN  2023-01-05    4\n",
       " 5  21   2  33.0  dog  apple  2023-01-06    5\n",
       " 6  83  88   NaN  cat  apple  2023-01-07    6\n",
       " 7  87  30  76.0  dog  apple  2023-01-08    7\n",
       " 8  75  38  58.0  cat    NaN  2023-01-09    8\n",
       " 9  75   2   NaN  dog  apple  2023-01-10    9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2 = df[['A', 'B']].copy()\n",
    "df2['key'] = list(range(10))\n",
    "df['key'] = list(range(10))\n",
    "\n",
    "merged_df = pd.merge(df, df2, on='key', how='inner').fillna(0)\n",
    "\n",
    "df_left = pd.DataFrame({'id': [1, 2], 'val1': ['x', 'y']})\n",
    "df_right = pd.DataFrame({'ref': [2, 3], 'val2': ['a', 'b']})\n",
    "left_join = pd.merge(df_left, df_right, left_on='id', right_on='ref', how='left')\n",
    "\n",
    "df_concat = pd.concat([df, df2], axis=1)\n",
    "df_concat = df_concat.loc[:, ~df_concat.columns.duplicated()]\n",
    "\n",
    "merged_df, left_join, df_concat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc98e4",
   "metadata": {},
   "source": [
    "## 4. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88d93b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8424\\3371770286.py:6: FutureWarning: The provided callable <function mean at 0x00000233A12D3920> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  pivot_table = df.pivot_table(values='A', index='D', columns='E', aggfunc=np.mean)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     mean        std\n",
       " D                   \n",
       " cat  57.2  26.480181\n",
       " dog  69.6  28.492104,\n",
       " D\n",
       " cat    16.911535\n",
       " dog    18.654758\n",
       " Name: A, dtype: float64,\n",
       " E    apple\n",
       " D         \n",
       " cat   49.0\n",
       " dog   69.6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grouped = df.groupby('D')['A'].agg(['mean', 'std'])\n",
    "\n",
    "sum_grouped = df.groupby('D')['A'].sum()\n",
    "sum_grouped_np = np.sqrt(sum_grouped)\n",
    "\n",
    "pivot_table = df.pivot_table(values='A', index='D', columns='E', aggfunc=np.mean)\n",
    "\n",
    "grouped, sum_grouped_np, pivot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62da82a",
   "metadata": {},
   "source": [
    "## 5. Array Operations and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ace4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2704, 8649,  225, 5184, 3721,  441, 6889, 7569, 5625, 5625]),\n",
       " array([[52],\n",
       "        [93],\n",
       "        [15],\n",
       "        [72],\n",
       "        [61],\n",
       "        [21],\n",
       "        [83],\n",
       "        [87],\n",
       "        [75],\n",
       "        [75]]),\n",
       "     A   B     C    D      E        Date  key  reshaped_A\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01    0          52\n",
       " 1  93  24  64.0  dog  apple  2023-01-02    1          93\n",
       " 3  72  22   NaN  dog  apple  2023-01-04    3          72\n",
       " 4  61  53  21.0  cat    NaN  2023-01-05    4          61\n",
       " 6  83  88   NaN  cat  apple  2023-01-07    6          83\n",
       " 7  87  30  76.0  dog  apple  2023-01-08    7          87\n",
       " 8  75  38  58.0  cat    NaN  2023-01-09    8          75\n",
       " 9  75   2   NaN  dog  apple  2023-01-10    9          75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr = df['A'].values\n",
    "arr_squared = arr ** 2\n",
    "\n",
    "reshaped_arr = arr.reshape(-1, 1)\n",
    "df['reshaped_A'] = reshaped_arr\n",
    "\n",
    "filtered_df = df[df['A'] > 50]\n",
    "\n",
    "arr_squared, reshaped_arr, filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff637b",
   "metadata": {},
   "source": [
    "## 6. Broadcasting and Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd87d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   broadcasted  multi_column_sum\n",
       " 0           53               140\n",
       " 1           94               117\n",
       " 2           16                18\n",
       " 3           73                94\n",
       " 4           62               114\n",
       " 5           22                23\n",
       " 6           84               171\n",
       " 7           88               117\n",
       " 8           76               113\n",
       " 9           76                77,\n",
       "       A     B\n",
       " 0 -18.0  18.0\n",
       " 1  34.5 -34.5\n",
       " 2   6.0  -6.0\n",
       " 3  25.0 -25.0\n",
       " 4   4.0  -4.0\n",
       " 5   9.5  -9.5\n",
       " 6  -2.5   2.5\n",
       " 7  28.5 -28.5\n",
       " 8  18.5 -18.5\n",
       " 9  36.5 -36.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "broadcast_array = np.array([1])\n",
    "df['broadcasted'] = df['A'] + broadcast_array[0]\n",
    "\n",
    "df['multi_column_sum'] = np.add(df['A'], df['B'])\n",
    "\n",
    "row_means = df.iloc[:, 0:2].mean(axis=1)\n",
    "df_broadcast = df.iloc[:, 0:2].subtract(row_means, axis=0)\n",
    "\n",
    "df[['broadcasted', 'multi_column_sum']], df_broadcast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa68cd0",
   "metadata": {},
   "source": [
    "## 7. Linear Algebra with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffedb3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 2.]),\n",
       " np.int64(24626),\n",
       "        0      1\n",
       " 0  46632  24626\n",
       " 1  24626  21718)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Solve system: 2x + y = 8; 3x + 2y = 13\n",
    "A_sys = np.array([[2, 1], [3, 2]])\n",
    "b_sys = np.array([8, 13])\n",
    "solution = np.linalg.solve(A_sys, b_sys)\n",
    "\n",
    "df_dot = np.dot(df['A'], df['B'])\n",
    "\n",
    "matrix_mult = pd.DataFrame(np.dot(df[['A', 'B']].values.T, df[['A', 'B']].values))\n",
    "\n",
    "solution, df_dot, matrix_mult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71980781",
   "metadata": {},
   "source": [
    "## 8. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e3467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8424\\3310742839.py:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_masked['C'][mask] = -1\n",
      "C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8424\\3310742839.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_masked['C'][mask] = -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    A   B     C    D      E        Date  key  reshaped_A  broadcasted  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01    0          52           53   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02    1          93           94   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03    2          15           16   \n",
       " 3  72  22  40.5  dog  apple  2023-01-04    3          72           73   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05    4          61           62   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06    5          21           22   \n",
       " 6  83  88  54.5  cat  apple  2023-01-07    6          83           84   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08    7          87           88   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09    8          75           76   \n",
       " 9  75   2  58.0  dog  apple  2023-01-10    9          75           76   \n",
       " \n",
       "    multi_column_sum  \n",
       " 0               140  \n",
       " 1               117  \n",
       " 2                18  \n",
       " 3                94  \n",
       " 4               114  \n",
       " 5                23  \n",
       " 6               171  \n",
       " 7               117  \n",
       " 8               113  \n",
       " 9                77  ,\n",
       "     A   B     C    D      E        Date  key  reshaped_A  broadcasted  \\\n",
       " 0  52  88  -1.0  cat    NaN  2023-01-01    0          52           53   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02    1          93           94   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03    2          15           16   \n",
       " 3  72  22  -1.0  dog  apple  2023-01-04    3          72           73   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05    4          61           62   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06    5          21           22   \n",
       " 6  83  88  -1.0  cat  apple  2023-01-07    6          83           84   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08    7          87           88   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09    8          75           76   \n",
       " 9  75   2  -1.0  dog  apple  2023-01-10    9          75           76   \n",
       " \n",
       "    multi_column_sum  \n",
       " 0               140  \n",
       " 1               117  \n",
       " 2                18  \n",
       " 3                94  \n",
       " 4               114  \n",
       " 5                23  \n",
       " 6               171  \n",
       " 7               117  \n",
       " 8               113  \n",
       " 9                77  ,\n",
       "     A   B     C    D      E        Date  key  reshaped_A  broadcasted  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01    0          52           53   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02    1          93           94   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03    2          15           16   \n",
       " 3  72  22   NaN  dog  apple  2023-01-04    3          72           73   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05    4          61           62   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06    5          21           22   \n",
       " 6  83  88   NaN  cat  apple  2023-01-07    6          83           84   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08    7          87           88   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09    8          75           76   \n",
       " 9  75   2   NaN  dog  apple  2023-01-10    9          75           76   \n",
       " \n",
       "    multi_column_sum  \n",
       " 0               140  \n",
       " 1               117  \n",
       " 2                18  \n",
       " 3                94  \n",
       " 4               114  \n",
       " 5                23  \n",
       " 6               171  \n",
       " 7               117  \n",
       " 8               113  \n",
       " 9                77  )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_interp = df.copy()\n",
    "df_interp['C'] = df_interp['C'].interpolate(method='linear')\n",
    "\n",
    "mask = df['C'].isna()\n",
    "df_masked = df.copy()\n",
    "df_masked['C'][mask] = -1\n",
    "\n",
    "q1 = df['C'].quantile(0.25)\n",
    "q3 = df['C'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "outlier_mask = (df['C'] < (q1 - 1.5 * iqr)) | (df['C'] > (q3 + 1.5 * iqr))\n",
    "df_outliers_handled = df.copy()\n",
    "df_outliers_handled.loc[outlier_mask, 'C'] = df['C'].median()\n",
    "\n",
    "df_interp, df_masked, df_outliers_handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a56490",
   "metadata": {},
   "source": [
    "## 9. Advanced Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c54326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>rolling_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>15</td>\n",
       "      <td>53.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>72</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>61</td>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>21</td>\n",
       "      <td>51.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>83</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>87</td>\n",
       "      <td>63.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>75</td>\n",
       "      <td>81.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>75</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   A  rolling_mean\n",
       "0  2023-01-01  52           NaN\n",
       "1  2023-01-02  93           NaN\n",
       "2  2023-01-03  15     53.333333\n",
       "3  2023-01-04  72     60.000000\n",
       "4  2023-01-05  61     49.333333\n",
       "5  2023-01-06  21     51.333333\n",
       "6  2023-01-07  83     55.000000\n",
       "7  2023-01-08  87     63.666667\n",
       "8  2023-01-09  75     81.666667\n",
       "9  2023-01-10  75     79.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trend_df = df.groupby(['D', 'E'])['A'].mean().unstack()\n",
    "\n",
    "correlation = df[['A', 'B', 'C']].corr()\n",
    "\n",
    "df['rolling_mean'] = df['A'].rolling(window=3).mean()\n",
    "df[['Date', 'A', 'rolling_mean']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa4781",
   "metadata": {},
   "source": [
    "## 10. DataFrame and Array Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86607de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m arr \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 2\u001b[0m arr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      3\u001b[0m df_transformed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(arr, columns\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      5\u001b[0m random_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = df.values\n",
    "arr += 1\n",
    "df_transformed = pd.DataFrame(arr, columns=df.columns)\n",
    "\n",
    "random_df = pd.DataFrame(np.random.rand(10, 3), columns=['X', 'Y', 'Z'])\n",
    "filtered_random_df = random_df[(random_df['X'] > 0.5) & (random_df['Y'] < 0.5)]\n",
    "\n",
    "arr1 = np.array(df['A'])\n",
    "arr2 = np.array(df['B'])\n",
    "df_custom = pd.DataFrame(np.power(arr1, 2) + np.power(arr2, 2), columns=['custom_sum'])\n",
    "\n",
    "df_transformed, filtered_random_df, df_custom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7761591",
   "metadata": {},
   "source": [
    "## 11. Data Reshaping and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf574c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[52, 93, 15, 72, 61],\n",
       "        [21, 83, 87, 75, 75]]),\n",
       "     A   B     C    D      E        Date  key  reshaped_A  broadcasted  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01    0          52           53   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02    1          93           94   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03    2          15           16   \n",
       " 3  72  22   NaN  dog  apple  2023-01-04    3          72           73   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05    4          61           62   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06    5          21           22   \n",
       " 6  83  88   NaN  cat  apple  2023-01-07    6          83           84   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08    7          87           88   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09    8          75           76   \n",
       " 9  75   2   NaN  dog  apple  2023-01-10    9          75           76   \n",
       " \n",
       "    multi_column_sum  rolling_mean  \n",
       " 0               140           NaN  \n",
       " 1               117           NaN  \n",
       " 2                18     53.333333  \n",
       " 3                94     60.000000  \n",
       " 4               114     49.333333  \n",
       " 5                23     51.333333  \n",
       " 6               171     55.000000  \n",
       " 7               117     63.666667  \n",
       " 8               113     81.666667  \n",
       " 9                77     79.000000  ,\n",
       "     0   1   2\n",
       " 0  18  20  25\n",
       " 1  15  16  14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reshaped = df['A'].values.reshape(2, 5)\n",
    "\n",
    "df1 = df.head(5)\n",
    "df2 = df.tail(5)\n",
    "stacked = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "array3d = np.random.randint(1, 10, size=(2, 3, 3))\n",
    "df_3d = pd.DataFrame(array3d.reshape(6, 3))\n",
    "df_grouped_3d = df_3d.groupby(df_3d.index % 2).sum()\n",
    "\n",
    "reshaped, stacked, df_grouped_3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37434a",
   "metadata": {},
   "source": [
    "## 12. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc7160d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date   A  moving_avg  days_diff\n",
       " 0 2023-01-01  52         NaN        0.0\n",
       " 1 2023-01-02  93         NaN        1.0\n",
       " 2 2023-01-03  15   53.333333        1.0\n",
       " 3 2023-01-04  72   60.000000        1.0\n",
       " 4 2023-01-05  61   49.333333        1.0\n",
       " 5 2023-01-06  21   51.333333        1.0\n",
       " 6 2023-01-07  83   55.000000        1.0\n",
       " 7 2023-01-08  87   63.666667        1.0\n",
       " 8 2023-01-09  75   81.666667        1.0\n",
       " 9 2023-01-10  75   79.000000        1.0,\n",
       " 0    NaN\n",
       " 1    1.0\n",
       " 2    1.0\n",
       " 3    1.0\n",
       " 4    1.0\n",
       " 5    1.0\n",
       " 6    1.0\n",
       " 7    1.0\n",
       " 8    1.0\n",
       " 9    1.0\n",
       " Name: Date, dtype: float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['days_diff'] = (df['Date'] - df['Date'].shift()).dt.days.fillna(0)\n",
    "\n",
    "df['moving_avg'] = df['A'].rolling(window=3).mean()\n",
    "\n",
    "datetime_diff = df['Date'].diff().dt.days\n",
    "\n",
    "df[['Date', 'A', 'moving_avg', 'days_diff']], datetime_diff\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
