{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54603f15",
   "metadata": {},
   "source": [
    "## 1. Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262ad8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    A   B     C    D      E        Date\n",
       " 1  93  24  64.0  dog  apple  2023-01-02\n",
       " 2  15   3  60.0  cat  apple  2023-01-03\n",
       " 5  21   2  33.0  dog  apple  2023-01-06\n",
       " 7  87  30  76.0  dog  apple  2023-01-08,\n",
       "     A   B     C    D      E        Date\n",
       " 0  52  88  52.0  cat    NaN  2023-01-01\n",
       " 1  93  24  64.0  dog  apple  2023-01-02\n",
       " 2  15   3  60.0  cat  apple  2023-01-03\n",
       " 3  72  22  52.0  dog  apple  2023-01-04\n",
       " 4  61  53  21.0  cat    NaN  2023-01-05\n",
       " 5  21   2  33.0  dog  apple  2023-01-06\n",
       " 6  83  88  52.0  cat  apple  2023-01-07\n",
       " 7  87  30  76.0  dog  apple  2023-01-08\n",
       " 8  75  38  58.0  cat    NaN  2023-01-09\n",
       " 9  75   2  52.0  dog  apple  2023-01-10,\n",
       "     A   B     C    D      E        Date\n",
       " 0  52  88   NaN  cat  apple  2023-01-01\n",
       " 1  93  24  64.0  dog  apple  2023-01-02\n",
       " 2  15   3  60.0  cat  apple  2023-01-03\n",
       " 3  72  22   NaN  dog  apple  2023-01-04\n",
       " 4  61  53  21.0  cat  apple  2023-01-05\n",
       " 5  21   2  33.0  dog  apple  2023-01-06\n",
       " 6  83  88   NaN  cat  apple  2023-01-07\n",
       " 7  87  30  76.0  dog  apple  2023-01-08\n",
       " 8  75  38  58.0  cat  apple  2023-01-09\n",
       " 9  75   2   NaN  dog  apple  2023-01-10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\syeda\\Downloads\\sample_data.csv\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropna = df.dropna()\n",
    "\n",
    "# Replace missing numerical values with mean\n",
    "df_fill_mean = df.copy()\n",
    "df_fill_mean['C'] = df_fill_mean['C'].fillna(df_fill_mean['C'].mean())\n",
    "\n",
    "# Replace missing categorical values with mode\n",
    "df_fill_mode = df.copy()\n",
    "df_fill_mode['E'] = df_fill_mode['E'].fillna(df_fill_mode['E'].mode()[0])\n",
    "\n",
    "df_dropna, df_fill_mean, df_fill_mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa8bde",
   "metadata": {},
   "source": [
    "## 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae164c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>A_plus_B</th>\n",
       "      <th>sqrt_A</th>\n",
       "      <th>A_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>88</td>\n",
       "      <td>140</td>\n",
       "      <td>7.211103</td>\n",
       "      <td>0.474359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>117</td>\n",
       "      <td>9.643651</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3.872983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>22</td>\n",
       "      <td>94</td>\n",
       "      <td>8.485281</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>114</td>\n",
       "      <td>7.810250</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>171</td>\n",
       "      <td>9.110434</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87</td>\n",
       "      <td>30</td>\n",
       "      <td>117</td>\n",
       "      <td>9.327379</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>113</td>\n",
       "      <td>8.660254</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>8.660254</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B  A_plus_B    sqrt_A  A_normalized\n",
       "0  52  88       140  7.211103      0.474359\n",
       "1  93  24       117  9.643651      1.000000\n",
       "2  15   3        18  3.872983      0.000000\n",
       "3  72  22        94  8.485281      0.730769\n",
       "4  61  53       114  7.810250      0.589744\n",
       "5  21   2        23  4.582576      0.076923\n",
       "6  83  88       171  9.110434      0.871795\n",
       "7  87  30       117  9.327379      0.923077\n",
       "8  75  38       113  8.660254      0.769231\n",
       "9  75   2        77  8.660254      0.769231"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df['A_plus_B'] = np.add(df['A'], df['B'])\n",
    "df['sqrt_A'] = np.sqrt(df['A'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['A_normalized'] = scaler.fit_transform(df[['A']])\n",
    "\n",
    "df[['A', 'B', 'A_plus_B', 'sqrt_A', 'A_normalized']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b3291",
   "metadata": {},
   "source": [
    "## 3. Merging and Joining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72f65fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   A_x  B_x     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  \\\n",
       " 0   52   88   0.0  cat      0  2023-01-01       140  7.211103      0.474359   \n",
       " 1   93   24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000   \n",
       " 2   15    3  60.0  cat  apple  2023-01-03        18  3.872983      0.000000   \n",
       " 3   72   22   0.0  dog  apple  2023-01-04        94  8.485281      0.730769   \n",
       " 4   61   53  21.0  cat      0  2023-01-05       114  7.810250      0.589744   \n",
       " 5   21    2  33.0  dog  apple  2023-01-06        23  4.582576      0.076923   \n",
       " 6   83   88   0.0  cat  apple  2023-01-07       171  9.110434      0.871795   \n",
       " 7   87   30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077   \n",
       " 8   75   38  58.0  cat      0  2023-01-09       113  8.660254      0.769231   \n",
       " 9   75    2   0.0  dog  apple  2023-01-10        77  8.660254      0.769231   \n",
       " \n",
       "    key  A_y  B_y  \n",
       " 0    0   52   88  \n",
       " 1    1   93   24  \n",
       " 2    2   15    3  \n",
       " 3    3   72   22  \n",
       " 4    4   61   53  \n",
       " 5    5   21    2  \n",
       " 6    6   83   88  \n",
       " 7    7   87   30  \n",
       " 8    8   75   38  \n",
       " 9    9   75    2  ,\n",
       "    id val1  ref val2\n",
       " 0   1    x  NaN  NaN\n",
       " 1   2    y  2.0    a,\n",
       "     A   B     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  key\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01       140  7.211103      0.474359    0\n",
       " 1  93  24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000    1\n",
       " 2  15   3  60.0  cat  apple  2023-01-03        18  3.872983      0.000000    2\n",
       " 3  72  22   NaN  dog  apple  2023-01-04        94  8.485281      0.730769    3\n",
       " 4  61  53  21.0  cat    NaN  2023-01-05       114  7.810250      0.589744    4\n",
       " 5  21   2  33.0  dog  apple  2023-01-06        23  4.582576      0.076923    5\n",
       " 6  83  88   NaN  cat  apple  2023-01-07       171  9.110434      0.871795    6\n",
       " 7  87  30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077    7\n",
       " 8  75  38  58.0  cat    NaN  2023-01-09       113  8.660254      0.769231    8\n",
       " 9  75   2   NaN  dog  apple  2023-01-10        77  8.660254      0.769231    9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2 = df[['A', 'B']].copy()\n",
    "df2['key'] = list(range(10))\n",
    "df['key'] = list(range(10))\n",
    "\n",
    "merged_df = pd.merge(df, df2, on='key', how='inner').fillna(0)\n",
    "\n",
    "df_left = pd.DataFrame({'id': [1, 2], 'val1': ['x', 'y']})\n",
    "df_right = pd.DataFrame({'ref': [2, 3], 'val2': ['a', 'b']})\n",
    "left_join = pd.merge(df_left, df_right, left_on='id', right_on='ref', how='left')\n",
    "\n",
    "df_concat = pd.concat([df, df2], axis=1)\n",
    "df_concat = df_concat.loc[:, ~df_concat.columns.duplicated()]\n",
    "\n",
    "merged_df, left_join, df_concat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc98e4",
   "metadata": {},
   "source": [
    "## 4. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d93b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8888\\3371770286.py:6: FutureWarning: The provided callable <function mean at 0x0000027EFF74B1A0> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  pivot_table = df.pivot_table(values='A', index='D', columns='E', aggfunc=np.mean)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     mean        std\n",
       " D                   \n",
       " cat  57.2  26.480181\n",
       " dog  69.6  28.492104,\n",
       " D\n",
       " cat    16.911535\n",
       " dog    18.654758\n",
       " Name: A, dtype: float64,\n",
       " E    apple\n",
       " D         \n",
       " cat   49.0\n",
       " dog   69.6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grouped = df.groupby('D')['A'].agg(['mean', 'std'])\n",
    "\n",
    "sum_grouped = df.groupby('D')['A'].sum()\n",
    "sum_grouped_np = np.sqrt(sum_grouped)\n",
    "\n",
    "pivot_table = df.pivot_table(values='A', index='D', columns='E', aggfunc=np.mean)\n",
    "\n",
    "grouped, sum_grouped_np, pivot_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62da82a",
   "metadata": {},
   "source": [
    "## 5. Array Operations and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ace4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2704, 8649,  225, 5184, 3721,  441, 6889, 7569, 5625, 5625],\n",
       "       dtype=int64),\n",
       " array([[52],\n",
       "        [93],\n",
       "        [15],\n",
       "        [72],\n",
       "        [61],\n",
       "        [21],\n",
       "        [83],\n",
       "        [87],\n",
       "        [75],\n",
       "        [75]], dtype=int64),\n",
       "     A   B     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01       140  7.211103      0.474359   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000   \n",
       " 3  72  22   NaN  dog  apple  2023-01-04        94  8.485281      0.730769   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05       114  7.810250      0.589744   \n",
       " 6  83  88   NaN  cat  apple  2023-01-07       171  9.110434      0.871795   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09       113  8.660254      0.769231   \n",
       " 9  75   2   NaN  dog  apple  2023-01-10        77  8.660254      0.769231   \n",
       " \n",
       "    key  reshaped_A  \n",
       " 0    0          52  \n",
       " 1    1          93  \n",
       " 3    3          72  \n",
       " 4    4          61  \n",
       " 6    6          83  \n",
       " 7    7          87  \n",
       " 8    8          75  \n",
       " 9    9          75  )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr = df['A'].values\n",
    "arr_squared = arr ** 2\n",
    "\n",
    "reshaped_arr = arr.reshape(-1, 1)\n",
    "df['reshaped_A'] = reshaped_arr\n",
    "\n",
    "filtered_df = df[df['A'] > 50]\n",
    "\n",
    "arr_squared, reshaped_arr, filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff637b",
   "metadata": {},
   "source": [
    "## 6. Broadcasting and Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd87d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   broadcasted  multi_column_sum\n",
       " 0           53               140\n",
       " 1           94               117\n",
       " 2           16                18\n",
       " 3           73                94\n",
       " 4           62               114\n",
       " 5           22                23\n",
       " 6           84               171\n",
       " 7           88               117\n",
       " 8           76               113\n",
       " 9           76                77,\n",
       "       A     B\n",
       " 0 -18.0  18.0\n",
       " 1  34.5 -34.5\n",
       " 2   6.0  -6.0\n",
       " 3  25.0 -25.0\n",
       " 4   4.0  -4.0\n",
       " 5   9.5  -9.5\n",
       " 6  -2.5   2.5\n",
       " 7  28.5 -28.5\n",
       " 8  18.5 -18.5\n",
       " 9  36.5 -36.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "broadcast_array = np.array([1])\n",
    "df['broadcasted'] = df['A'] + broadcast_array[0]\n",
    "\n",
    "df['multi_column_sum'] = np.add(df['A'], df['B'])\n",
    "\n",
    "row_means = df.iloc[:, 0:2].mean(axis=1)\n",
    "df_broadcast = df.iloc[:, 0:2].subtract(row_means, axis=0)\n",
    "\n",
    "df[['broadcasted', 'multi_column_sum']], df_broadcast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa68cd0",
   "metadata": {},
   "source": [
    "## 7. Linear Algebra with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffedb3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 2.]),\n",
       " 24626,\n",
       "        0      1\n",
       " 0  46632  24626\n",
       " 1  24626  21718)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Solve system: 2x + y = 8; 3x + 2y = 13\n",
    "A_sys = np.array([[2, 1], [3, 2]])\n",
    "b_sys = np.array([8, 13])\n",
    "solution = np.linalg.solve(A_sys, b_sys)\n",
    "\n",
    "df_dot = np.dot(df['A'], df['B'])\n",
    "\n",
    "matrix_mult = pd.DataFrame(np.dot(df[['A', 'B']].values.T, df[['A', 'B']].values))\n",
    "\n",
    "solution, df_dot, matrix_mult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71980781",
   "metadata": {},
   "source": [
    "## 8. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4e3467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8888\\3310742839.py:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_masked['C'][mask] = -1\n",
      "C:\\Users\\syeda\\AppData\\Local\\Temp\\ipykernel_8888\\3310742839.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_masked['C'][mask] = -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    A   B     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01       140  7.211103      0.474359   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03        18  3.872983      0.000000   \n",
       " 3  72  22  40.5  dog  apple  2023-01-04        94  8.485281      0.730769   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05       114  7.810250      0.589744   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06        23  4.582576      0.076923   \n",
       " 6  83  88  54.5  cat  apple  2023-01-07       171  9.110434      0.871795   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09       113  8.660254      0.769231   \n",
       " 9  75   2  58.0  dog  apple  2023-01-10        77  8.660254      0.769231   \n",
       " \n",
       "    key  reshaped_A  broadcasted  multi_column_sum  \n",
       " 0    0          52           53               140  \n",
       " 1    1          93           94               117  \n",
       " 2    2          15           16                18  \n",
       " 3    3          72           73                94  \n",
       " 4    4          61           62               114  \n",
       " 5    5          21           22                23  \n",
       " 6    6          83           84               171  \n",
       " 7    7          87           88               117  \n",
       " 8    8          75           76               113  \n",
       " 9    9          75           76                77  ,\n",
       "     A   B     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  \\\n",
       " 0  52  88  -1.0  cat    NaN  2023-01-01       140  7.211103      0.474359   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03        18  3.872983      0.000000   \n",
       " 3  72  22  -1.0  dog  apple  2023-01-04        94  8.485281      0.730769   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05       114  7.810250      0.589744   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06        23  4.582576      0.076923   \n",
       " 6  83  88  -1.0  cat  apple  2023-01-07       171  9.110434      0.871795   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09       113  8.660254      0.769231   \n",
       " 9  75   2  -1.0  dog  apple  2023-01-10        77  8.660254      0.769231   \n",
       " \n",
       "    key  reshaped_A  broadcasted  multi_column_sum  \n",
       " 0    0          52           53               140  \n",
       " 1    1          93           94               117  \n",
       " 2    2          15           16                18  \n",
       " 3    3          72           73                94  \n",
       " 4    4          61           62               114  \n",
       " 5    5          21           22                23  \n",
       " 6    6          83           84               171  \n",
       " 7    7          87           88               117  \n",
       " 8    8          75           76               113  \n",
       " 9    9          75           76                77  ,\n",
       "     A   B     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01       140  7.211103      0.474359   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03        18  3.872983      0.000000   \n",
       " 3  72  22   NaN  dog  apple  2023-01-04        94  8.485281      0.730769   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05       114  7.810250      0.589744   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06        23  4.582576      0.076923   \n",
       " 6  83  88   NaN  cat  apple  2023-01-07       171  9.110434      0.871795   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09       113  8.660254      0.769231   \n",
       " 9  75   2   NaN  dog  apple  2023-01-10        77  8.660254      0.769231   \n",
       " \n",
       "    key  reshaped_A  broadcasted  multi_column_sum  \n",
       " 0    0          52           53               140  \n",
       " 1    1          93           94               117  \n",
       " 2    2          15           16                18  \n",
       " 3    3          72           73                94  \n",
       " 4    4          61           62               114  \n",
       " 5    5          21           22                23  \n",
       " 6    6          83           84               171  \n",
       " 7    7          87           88               117  \n",
       " 8    8          75           76               113  \n",
       " 9    9          75           76                77  )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_interp = df.copy()\n",
    "df_interp['C'] = df_interp['C'].interpolate(method='linear')\n",
    "\n",
    "mask = df['C'].isna()\n",
    "df_masked = df.copy()\n",
    "df_masked['C'][mask] = -1\n",
    "\n",
    "q1 = df['C'].quantile(0.25)\n",
    "q3 = df['C'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "outlier_mask = (df['C'] < (q1 - 1.5 * iqr)) | (df['C'] > (q3 + 1.5 * iqr))\n",
    "df_outliers_handled = df.copy()\n",
    "df_outliers_handled.loc[outlier_mask, 'C'] = df['C'].median()\n",
    "\n",
    "df_interp, df_masked, df_outliers_handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a56490",
   "metadata": {},
   "source": [
    "## 9. Advanced Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c54326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>rolling_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>15</td>\n",
       "      <td>53.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>72</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>61</td>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>21</td>\n",
       "      <td>51.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>83</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>87</td>\n",
       "      <td>63.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>75</td>\n",
       "      <td>81.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>75</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   A  rolling_mean\n",
       "0  2023-01-01  52           NaN\n",
       "1  2023-01-02  93           NaN\n",
       "2  2023-01-03  15     53.333333\n",
       "3  2023-01-04  72     60.000000\n",
       "4  2023-01-05  61     49.333333\n",
       "5  2023-01-06  21     51.333333\n",
       "6  2023-01-07  83     55.000000\n",
       "7  2023-01-08  87     63.666667\n",
       "8  2023-01-09  75     81.666667\n",
       "9  2023-01-10  75     79.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trend_df = df.groupby(['D', 'E'])['A'].mean().unstack()\n",
    "\n",
    "correlation = df[['A', 'B', 'C']].corr()\n",
    "\n",
    "df['rolling_mean'] = df['A'].rolling(window=3).mean()\n",
    "df[['Date', 'A', 'rolling_mean']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa4781",
   "metadata": {},
   "source": [
    "## 10. DataFrame and Array Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86607de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformed Numeric DataFrame:\n",
      "      A     B     C\n",
      "0  53.0  89.0   NaN\n",
      "1  94.0  25.0  65.0\n",
      "2  16.0   4.0  61.0\n",
      "3  73.0  23.0   NaN\n",
      "4  62.0  54.0  22.0\n",
      "5  22.0   3.0  34.0\n",
      "6  84.0  89.0   NaN\n",
      "7  88.0  31.0  77.0\n",
      "8  76.0  39.0  59.0\n",
      "9  76.0   3.0   NaN\n",
      "\n",
      "✅ Filtered Random DataFrame:\n",
      "          X         Y         Z\n",
      "7  0.816023  0.233229  0.529765\n",
      "9  0.642664  0.475739  0.074028\n",
      "\n",
      "✅ Custom Feature DataFrame:\n",
      "   custom_sum\n",
      "0     10448.0\n",
      "1      9225.0\n",
      "2       234.0\n",
      "3      5668.0\n",
      "4      6530.0\n",
      "5       445.0\n",
      "6     14633.0\n",
      "7      8469.0\n",
      "8      7069.0\n",
      "9      5629.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(\"C:/Users/syeda/Downloads/sample_data.csv\")\n",
    "\n",
    "# ✅ Step 1: Only apply numeric operation to numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "arr = numeric_df.values\n",
    "arr += 1\n",
    "df_transformed = pd.DataFrame(arr, columns=numeric_df.columns)\n",
    "\n",
    "# ✅ Step 2: Filter random DataFrame\n",
    "random_df = pd.DataFrame(np.random.rand(10, 3), columns=['X', 'Y', 'Z'])\n",
    "filtered_random_df = random_df[(random_df['X'] > 0.5) & (random_df['Y'] < 0.5)]\n",
    "\n",
    "# ✅ Step 3: Custom feature from A and B\n",
    "arr1 = np.array(df['A'], dtype=float)\n",
    "arr2 = np.array(df['B'], dtype=float)\n",
    "df_custom = pd.DataFrame(np.power(arr1, 2) + np.power(arr2, 2), columns=['custom_sum'])\n",
    "\n",
    "# ✅ Display all three outputs\n",
    "print(\"✅ Transformed Numeric DataFrame:\")\n",
    "print(df_transformed)\n",
    "\n",
    "print(\"\\n✅ Filtered Random DataFrame:\")\n",
    "print(filtered_random_df)\n",
    "\n",
    "print(\"\\n✅ Custom Feature DataFrame:\")\n",
    "print(df_custom)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7761591",
   "metadata": {},
   "source": [
    "## 11. Data Reshaping and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf574c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[52, 93, 15, 72, 61],\n",
       "        [21, 83, 87, 75, 75]], dtype=int64),\n",
       "     A   B     C    D      E        Date  A_plus_B    sqrt_A  A_normalized  \\\n",
       " 0  52  88   NaN  cat    NaN  2023-01-01       140  7.211103      0.474359   \n",
       " 1  93  24  64.0  dog  apple  2023-01-02       117  9.643651      1.000000   \n",
       " 2  15   3  60.0  cat  apple  2023-01-03        18  3.872983      0.000000   \n",
       " 3  72  22   NaN  dog  apple  2023-01-04        94  8.485281      0.730769   \n",
       " 4  61  53  21.0  cat    NaN  2023-01-05       114  7.810250      0.589744   \n",
       " 5  21   2  33.0  dog  apple  2023-01-06        23  4.582576      0.076923   \n",
       " 6  83  88   NaN  cat  apple  2023-01-07       171  9.110434      0.871795   \n",
       " 7  87  30  76.0  dog  apple  2023-01-08       117  9.327379      0.923077   \n",
       " 8  75  38  58.0  cat    NaN  2023-01-09       113  8.660254      0.769231   \n",
       " 9  75   2   NaN  dog  apple  2023-01-10        77  8.660254      0.769231   \n",
       " \n",
       "    key  reshaped_A  broadcasted  multi_column_sum  rolling_mean  \n",
       " 0    0          52           53               140           NaN  \n",
       " 1    1          93           94               117           NaN  \n",
       " 2    2          15           16                18     53.333333  \n",
       " 3    3          72           73                94     60.000000  \n",
       " 4    4          61           62               114     49.333333  \n",
       " 5    5          21           22                23     51.333333  \n",
       " 6    6          83           84               171     55.000000  \n",
       " 7    7          87           88               117     63.666667  \n",
       " 8    8          75           76               113     81.666667  \n",
       " 9    9          75           76                77     79.000000  ,\n",
       "     0   1   2\n",
       " 0  18   9  14\n",
       " 1  10  18   6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reshaped = df['A'].values.reshape(2, 5)\n",
    "\n",
    "df1 = df.head(5)\n",
    "df2 = df.tail(5)\n",
    "stacked = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "array3d = np.random.randint(1, 10, size=(2, 3, 3))\n",
    "df_3d = pd.DataFrame(array3d.reshape(6, 3))\n",
    "df_grouped_3d = df_3d.groupby(df_3d.index % 2).sum()\n",
    "\n",
    "reshaped, stacked, df_grouped_3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37434a",
   "metadata": {},
   "source": [
    "## 12. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc7160d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Date   A  moving_avg  days_diff\n",
       " 0 2023-01-01  52         NaN        0.0\n",
       " 1 2023-01-02  93         NaN        1.0\n",
       " 2 2023-01-03  15   53.333333        1.0\n",
       " 3 2023-01-04  72   60.000000        1.0\n",
       " 4 2023-01-05  61   49.333333        1.0\n",
       " 5 2023-01-06  21   51.333333        1.0\n",
       " 6 2023-01-07  83   55.000000        1.0\n",
       " 7 2023-01-08  87   63.666667        1.0\n",
       " 8 2023-01-09  75   81.666667        1.0\n",
       " 9 2023-01-10  75   79.000000        1.0,\n",
       " 0    NaN\n",
       " 1    1.0\n",
       " 2    1.0\n",
       " 3    1.0\n",
       " 4    1.0\n",
       " 5    1.0\n",
       " 6    1.0\n",
       " 7    1.0\n",
       " 8    1.0\n",
       " 9    1.0\n",
       " Name: Date, dtype: float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['days_diff'] = (df['Date'] - df['Date'].shift()).dt.days.fillna(0)\n",
    "\n",
    "df['moving_avg'] = df['A'].rolling(window=3).mean()\n",
    "\n",
    "datetime_diff = df['Date'].diff().dt.days\n",
    "\n",
    "df[['Date', 'A', 'moving_avg', 'days_diff']], datetime_diff\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
